{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAKmaffSKWe4",
        "outputId": "49ec3e5b-d697-4b73-90e2-a626f23c2bf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.51.2-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Downloading openai-1.51.2-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.7/383.7 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.6.1 openai-1.51.2\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzPJHymifkV_",
        "outputId": "a7ce8294-43c5-4782-c134-9add0df0afa8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (2024.2)\n"
          ]
        }
      ],
      "source": [
        "pip install pytz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFN77av9INfQ"
      },
      "source": [
        "#Api Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-xg90cfPX6i"
      },
      "outputs": [],
      "source": [
        "api_key = \"\"  # Insira sua chave de API do OpenAI aqui"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aAqNds2Qn2H"
      },
      "source": [
        "# Prompt utilizando a técnica Zero-Shot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lo8Uo_turPzi"
      },
      "outputs": [],
      "source": [
        "technique_use = \"zero_shot\"\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "Converta a seguinte descrição de caso de teste em um único cenário BDD, usando a sintaxe estrita de Gherkin. Certifique-se de que a saída contenha apenas a sintaxe de Gherkin para o cenário, sem comentários, explicações ou a palavra \"Feature\". Use o português para as descrições dos casos de teste e detalhes do cenário, mas mantenha as palavras-chave do Gherkin em inglês.\n",
        "\n",
        "Agora, converta a seguinte descrição de caso de teste em exatamente um cenário BDD usando a sintaxe estrita de Gherkin. A saída deve seguir exatamente o formato do exemplo fornecido e não conter nada além do cenário BDD. Somente as palavras-chave do Gherkin devem estar em inglês; todo o outro texto deve estar em português.\n",
        "\n",
        "Descrição do Caso de Teste:\n",
        "{test_case_description}\n",
        "\n",
        "Para um bom cenário BDD, certifique-se de declarar claramente o valor de negócio ou resultado esperado e mantenha o foco em uma única ação e seu resultado. Use apenas os passos essenciais (Given, When, Then, And) de forma clara e declarativa, evitando detalhes de implementação e repetições desnecessárias. Garanta que os cenários sejam independentes, utilizem uma terminologia de negócios consistente sem jargões técnicos e que os passos sejam escritos em terceira pessoa para evitar múltiplas interpretações.\n",
        "\n",
        "Certifique-se de que os cenários BDD tenham indentação consistente de dois espaços para cada passo sob 'Scenario', sem linhas em branco entre os passos, e uma linha em branco separando diferentes cenários.\n",
        "\n",
        "Siga esta estrutura para a saída:\n",
        "\n",
        "Scenario: [Descrição do Cenário]\n",
        "  Given [algum contexto inicial]\n",
        "    And [mais algum contexto, se houver]\n",
        "  When [uma ação é realizada]\n",
        "  Then [um conjunto específico de resultados deve ocorrer]\n",
        "    And [outro resultado, se houver]\n",
        "\n",
        "A resposta deve conter estritamente apenas a sintaxe válida de Gherkin e evitar qualquer informação ou comentário extra. A resposta deve conter apenas o texto BDD, sem formatação ou texto adicional (por exemplo, sem 'gherkin```'), e deve ser apenas um cenário BDD.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFuOXE-vvIQK"
      },
      "source": [
        "#Prompt utilizando a abordagem FEW-SHOT\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hg_5G4Q1vGp5"
      },
      "outputs": [],
      "source": [
        "technique_use = \"one_shot\"\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "Converta a seguinte descrição de caso de teste em um único cenário BDD, usando a sintaxe estrita de Gherkin. Certifique-se de que a saída contenha apenas a sintaxe de Gherkin para o cenário, sem comentários, explicações ou a palavra \"Feature\". Use o português para as descrições dos casos de teste e detalhes do cenário, mas mantenha as palavras-chave do Gherkin em inglês.\n",
        "\n",
        "# Exemplo\n",
        "# Descrição do caso de teste:\n",
        "# Usuário tenta login com credenciais inválidas.\n",
        "\n",
        "Scenario: Login com senha inválida\n",
        "  Given o usuário está na página de login\n",
        "    And o usuário insere um nome de usuário válido\n",
        "  When o usuário insere uma senha inválida e clica no botão de login\n",
        "  Then o sistema exibe uma mensagem de erro indicando que a senha está incorreta\n",
        "    And o campo de senha é limpo\n",
        "\n",
        "Agora, converta a seguinte descrição de caso de teste em exatamente um cenário BDD usando a sintaxe estrita de Gherkin. A saída deve seguir exatamente o formato do exemplo fornecido e não conter nada além do cenário BDD. Somente as palavras-chave do Gherkin devem estar em inglês; todo o outro texto deve estar em português.\n",
        "\n",
        "Descrição do Caso de Teste:\n",
        "{test_case_description}\n",
        "\n",
        "Para um bom cenário BDD, certifique-se de declarar claramente o valor de negócio ou resultado esperado e mantenha o foco em uma única ação e seu resultado. Use apenas os passos essenciais (Given, When, Then, And) de forma clara e declarativa, evitando detalhes de implementação e repetições desnecessárias. Garanta que os cenários sejam independentes, utilizem uma terminologia de negócios consistente sem jargões técnicos e que os passos sejam escritos em terceira pessoa para evitar múltiplas interpretações.\n",
        "Certifique-se de que os cenários BDD tenham indentação consistente de dois espaços para cada passo sob 'Scenario', sem linhas em branco entre os passos, e uma linha em branco separando diferentes cenários.\n",
        "\n",
        "Siga esta estrutura para a saída:\n",
        "\n",
        "Scenario: [Descrição do Cenário]\n",
        "  Given [algum contexto inicial]\n",
        "    And [mais algum contexto, se houver]\n",
        "  When [uma ação é realizada]\n",
        "  Then [um conjunto específico de resultados deve ocorrer]\n",
        "    And [outro resultado, se houver]\n",
        "\n",
        "A resposta deve conter estritamente apenas a sintaxe válida de Gherkin e evitar qualquer informação ou comentário extra. A resposta deve conter apenas o texto BDD, sem formatação ou texto adicional (por exemplo, sem 'gherkin```'), e deve ser apenas um cenário BDD.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTJ_3hSUYqFk"
      },
      "source": [
        "#Few-shot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRVd3wInYleY"
      },
      "outputs": [],
      "source": [
        "technique_use = \"few_shot\"\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "Converta a seguinte descrição de caso de teste em um único cenário BDD, usando a sintaxe estrita de Gherkin. Certifique-se de que a saída contenha apenas a sintaxe de Gherkin para o cenário, sem comentários, explicações ou a palavra \"Feature\". Use o português para as descrições dos casos de teste e detalhes do cenário, mas mantenha as palavras-chave do Gherkin em inglês.\n",
        "\n",
        "# Exemplo 1\n",
        "# Descrição do caso de teste:\n",
        "# Usuário tenta login com credenciais inválidas.\n",
        "\n",
        "Scenario: Login com senha inválida\n",
        "  Given o usuário está na página de login\n",
        "    And o usuário insere um nome de usuário válido\n",
        "  When o usuário insere uma senha inválida e clica no botão de login\n",
        "  Then o sistema exibe uma mensagem de erro indicando que a senha está incorreta\n",
        "    And o campo de senha é limpo\n",
        "\n",
        "# Exemplo 2\n",
        "# Descrição do caso de teste:\n",
        "# Usuário tenta redefinir a senha esquecida.\n",
        "\n",
        "Scenario: Redefinição de senha com e-mail válido\n",
        "  Given o usuário está na página de redefinição de senha\n",
        "    And o usuário insere um endereço de e-mail registrado\n",
        "  When o usuário clica no botão de enviar\n",
        "  Then o sistema exibe uma mensagem indicando que um link de redefinição de senha foi enviado para o e-mail do usuário\n",
        "    And o usuário é redirecionado para a página de login\n",
        "\n",
        "# Exemplo 3\n",
        "# Descrição do caso de teste:\n",
        "# Usuário adiciona um item ao carrinho de compras.\n",
        "\n",
        "Scenario: Adicionar item ao carrinho de compras\n",
        "  Given o usuário está na página de detalhes de um produto\n",
        "    And o produto está disponível em estoque\n",
        "  When o usuário clica no botão \"Adicionar ao carrinho\"\n",
        "  Then o item é adicionado ao carrinho de compras\n",
        "    And o sistema exibe uma mensagem de confirmação \"Item adicionado ao carrinho com sucesso\"\n",
        "    And o ícone do carrinho de compras é atualizado para refletir o novo item\n",
        "\n",
        "Agora, converta a seguinte descrição de caso de teste em exatamente um cenário BDD usando a sintaxe estrita de Gherkin. A saída deve seguir exatamente o formato do exemplo fornecido e não conter nada além do cenário BDD. Somente as palavras-chave do Gherkin devem estar em inglês; todo o outro texto deve estar em português.\n",
        "\n",
        "Descrição do Caso de Teste:\n",
        "{test_case_description}\n",
        "\n",
        "Para um bom cenário BDD, certifique-se de declarar claramente o valor de negócio ou resultado esperado e mantenha o foco em uma única ação e seu resultado. Use apenas os passos essenciais (Given, When, Then, And) de forma clara e declarativa, evitando detalhes de implementação e repetições desnecessárias. Garanta que os cenários sejam independentes, utilizem uma terminologia de negócios consistente sem jargões técnicos e que os passos sejam escritos em terceira pessoa para evitar múltiplas interpretações.\n",
        "Certifique-se de que os cenários BDD tenham indentação consistente de dois espaços para cada passo sob 'Scenario', sem linhas em branco entre os passos, e uma linha em branco separando diferentes cenários.\n",
        "\n",
        "Siga esta estrutura para a saída:\n",
        "\n",
        "Scenario: [Descrição do Cenário]\n",
        "  Given [algum contexto inicial]\n",
        "    And [mais algum contexto, se houver]\n",
        "  When [uma ação é realizada]\n",
        "  Then [um conjunto específico de resultados deve ocorrer]\n",
        "    And [outro resultado, se houver]\n",
        "\n",
        "A resposta deve conter estritamente apenas a sintaxe válida de Gherkin e evitar qualquer informação ou comentário extra. A resposta deve conter apenas o texto BDD, sem formatação ou texto adicional (por exemplo, sem 'gherkin```'), e deve ser apenas um cenário BDD.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDKnh03uH7bq"
      },
      "source": [
        "#Modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmwxZ4FwH8bv"
      },
      "outputs": [],
      "source": [
        "model_name = \"gpt-3.5-turbo-0125\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIw4RduIIYz9"
      },
      "outputs": [],
      "source": [
        "model_name = \"gpt-4o-mini\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEs5lk_3Ivw4"
      },
      "outputs": [],
      "source": [
        "model_name = \"gpt-4-turbo\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrcOJe1_cHuE"
      },
      "source": [
        "#Funções e Execução"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgupPPasL2on"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "from datetime import datetime\n",
        "import os\n",
        "import time\n",
        "import pytz\n",
        "\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "def generate_bdd(test_case_description, prompt_template, model_name, technique_use):\n",
        "    prompt = prompt_template.format(test_case_description=test_case_description)\n",
        "\n",
        "    try:\n",
        "        stream = client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            stream=True,\n",
        "            max_tokens=2048,\n",
        "            temperature=0.5,\n",
        "            top_p=0.8,\n",
        "            frequency_penalty=1.15,\n",
        "            presence_penalty=1.15,\n",
        "        )\n",
        "\n",
        "        bdd = []\n",
        "        for chunk in stream:\n",
        "            if chunk.choices[0].delta.content is not None:\n",
        "                bdd.append(chunk.choices[0].delta.content)\n",
        "\n",
        "        return ''.join(bdd).strip()  \n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao gerar BDD: {e}\")\n",
        "        return \"\"  \n",
        "\n",
        "df = pd.read_csv(\"casos_selecionados.csv\")\n",
        "\n",
        "def execute_rounds(num_exec, prompt_template, model_name, technique_use):\n",
        "    features_dir = f\"features-{model_name.replace('/', '-')}\"\n",
        "    os.makedirs(features_dir, exist_ok=True)\n",
        "\n",
        "    model_file_path = os.path.join(features_dir, \"model.txt\")\n",
        "    with open(model_file_path, \"w\") as model_file:\n",
        "        model_file.write(f\"Modelo utilizado: {model_name}\\n\")\n",
        "        model_file.write(f\"Técnica utilizada: {technique_use}\\n\")  \n",
        "\n",
        "    brt = pytz.timezone('America/Sao_Paulo')\n",
        "\n",
        "    for exec_num in range(1, num_exec + 1):\n",
        "        exec_dir = f\"{features_dir}/exec_{exec_num}\"\n",
        "        os.makedirs(exec_dir, exist_ok=True)\n",
        "\n",
        "        current_datetime = datetime.now(brt).strftime(\"%d/%m/%Y às %I:%M %p\")\n",
        "\n",
        "        for index, row in df.iterrows():\n",
        "            bdd = \"\"\n",
        "            retries = 0\n",
        "            max_retries = 1000 \n",
        "\n",
        "            while not bdd and retries < max_retries:\n",
        "                bdd = generate_bdd(row['case'], prompt_template, model_name, technique_use)\n",
        "                retries += 1\n",
        "                if not bdd:\n",
        "                    print(f\"Tentativa {retries}: BDD vazio para o caso {index + 1}. Tentando novamente...\")\n",
        "                    time.sleep(10)  \n",
        "\n",
        "            if not bdd:\n",
        "                print(f\"Erro: Não foi possível gerar um BDD válido para o caso {index + 1} após {max_retries} tentativas.\")\n",
        "            else:\n",
        "                file_name = f\"{exec_dir}/caso_{index + 1}.feature\"\n",
        "\n",
        "                with open(file_name, \"w\") as file:\n",
        "                    file.write(bdd)\n",
        "\n",
        "                if index < len(df) - 1:\n",
        "                    print(f\"Gerou o caso {index + 1}. Aguardando 10 segundos para o próximo caso.\")\n",
        "                    time.sleep(10)  \n",
        "\n",
        "        datetime_file_name = f\"{exec_dir}/timestamp.txt\"\n",
        "        with open(datetime_file_name, \"w\") as datetime_file:\n",
        "            datetime_file.write(current_datetime)\n",
        "\n",
        "        if exec_num < num_exec:\n",
        "            print(f\"Execução {exec_num} concluída. Aguardando 1 minuto para a próxima execução.\")\n",
        "            time.sleep(60)  \n",
        "\n",
        "num_exec = 1  \n",
        "\n",
        "execute_rounds(num_exec, prompt_template, model_name, technique_use)\n",
        "\n",
        "print(\"Arquivos gerados com sucesso.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8E08vpdWr_8t"
      },
      "source": [
        "#Com parâmetro SEED\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0Bpkzp4r_Xo",
        "outputId": "fd287054-6db4-44db-9466-d8ad0c4310f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gerou o caso 1. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 2. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 3. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 4. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 5. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 6. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 7. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 8. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 9. Aguardando 10 segundos para o próximo caso.\n",
            "Execução 1 concluída. Aguardando 1 minuto para a próxima execução.\n",
            "Gerou o caso 1. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 2. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 3. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 4. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 5. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 6. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 7. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 8. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 9. Aguardando 10 segundos para o próximo caso.\n",
            "Execução 2 concluída. Aguardando 1 minuto para a próxima execução.\n",
            "Gerou o caso 1. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 2. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 3. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 4. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 5. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 6. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 7. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 8. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 9. Aguardando 10 segundos para o próximo caso.\n",
            "Execução 3 concluída. Aguardando 1 minuto para a próxima execução.\n",
            "Gerou o caso 1. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 2. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 3. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 4. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 5. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 6. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 7. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 8. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 9. Aguardando 10 segundos para o próximo caso.\n",
            "Execução 4 concluída. Aguardando 1 minuto para a próxima execução.\n",
            "Gerou o caso 1. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 2. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 3. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 4. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 5. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 6. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 7. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 8. Aguardando 10 segundos para o próximo caso.\n",
            "Gerou o caso 9. Aguardando 10 segundos para o próximo caso.\n",
            "Arquivos gerados com sucesso.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "from datetime import datetime\n",
        "import os\n",
        "import time\n",
        "import pytz\n",
        "\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "def generate_bdd(test_case_description, prompt_template, model_name, technique_use, seed=None):\n",
        "    prompt = prompt_template.format(test_case_description=test_case_description)\n",
        "\n",
        "    try:\n",
        "        stream = client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            stream=True,\n",
        "            max_tokens=2048,\n",
        "            temperature=0.5,\n",
        "            top_p=0.8,\n",
        "            frequency_penalty=1.15,\n",
        "            presence_penalty=1.15,\n",
        "            seed=seed  \n",
        "        )\n",
        "\n",
        "        bdd = []\n",
        "        for chunk in stream:\n",
        "            if chunk.choices[0].delta.content is not None:\n",
        "                bdd.append(chunk.choices[0].delta.content)\n",
        "\n",
        "        return ''.join(bdd).strip()  \n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao gerar BDD: {e}\")\n",
        "        return \"\" \n",
        "\n",
        "df = pd.read_csv(\"casos_selecionados.csv\")\n",
        "\n",
        "def execute_rounds(num_exec, prompt_template, model_name, technique_use, seed=None):\n",
        "    features_dir = f\"features-{model_name.replace('/', '-')}\"\n",
        "    os.makedirs(features_dir, exist_ok=True)\n",
        "\n",
        "    model_file_path = os.path.join(features_dir, \"model.txt\")\n",
        "    with open(model_file_path, \"w\") as model_file:\n",
        "        model_file.write(f\"Modelo utilizado: {model_name}\\n\")\n",
        "        model_file.write(f\"Técnica utilizada: {technique_use}\\n\") \n",
        "\n",
        "    brt = pytz.timezone('America/Sao_Paulo')\n",
        "\n",
        "    for exec_num in range(1, num_exec + 1):\n",
        "        exec_dir = f\"{features_dir}/exec_{exec_num}\"\n",
        "        os.makedirs(exec_dir, exist_ok=True)\n",
        "\n",
        "        current_datetime = datetime.now(brt).strftime(\"%d/%m/%Y às %I:%M %p\")\n",
        "\n",
        "        for index, row in df.iterrows():\n",
        "            bdd = \"\"\n",
        "            retries = 0\n",
        "            max_retries = 1000  \n",
        "\n",
        "            while not bdd and retries < max_retries:\n",
        "                bdd = generate_bdd(row['case'], prompt_template, model_name, technique_use, seed)\n",
        "                retries += 1\n",
        "                if not bdd:\n",
        "                    print(f\"Tentativa {retries}: BDD vazio para o caso {index + 1}. Tentando novamente...\")\n",
        "                    time.sleep(10)  \n",
        "\n",
        "            if not bdd:\n",
        "                print(f\"Erro: Não foi possível gerar um BDD válido para o caso {index + 1} após {max_retries} tentativas.\")\n",
        "            else:\n",
        "                file_name = f\"{exec_dir}/caso_{index + 1}.feature\"\n",
        "\n",
        "                with open(file_name, \"w\") as file:\n",
        "                    file.write(bdd)\n",
        "\n",
        "                if index < len(df) - 1:\n",
        "                    print(f\"Gerou o caso {index + 1}. Aguardando 10 segundos para o próximo caso.\")\n",
        "                    time.sleep(10)  \n",
        "\n",
        "        datetime_file_name = f\"{exec_dir}/timestamp.txt\"\n",
        "        with open(datetime_file_name, \"w\") as datetime_file:\n",
        "            datetime_file.write(current_datetime)\n",
        "\n",
        "        if exec_num < num_exec:\n",
        "            print(f\"Execução {exec_num} concluída. Aguardando 1 minuto para a próxima execução.\")\n",
        "            time.sleep(60)  \n",
        "\n",
        "num_exec = 5  \n",
        "seed = 42  \n",
        "\n",
        "execute_rounds(num_exec, prompt_template, model_name, technique_use, seed)\n",
        "\n",
        "print(\"Arquivos gerados com sucesso.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y7-CwV-Ip39"
      },
      "source": [
        "#Baixar pasta gerada em .zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "C1CxF20ZNAWM",
        "outputId": "5d34f544-552f-4dc9-fd5e-ecfdb68b8bf2"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_532ff778-bd10-4805-be20-0e6312914645\", \"features-gpt-4o-mini.zip\", 16993)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "features_dir = next((d for d in os.listdir() if d.startswith(\"features-\")), None)\n",
        "\n",
        "if features_dir:\n",
        "    with zipfile.ZipFile(f'{features_dir}.zip', 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, dirs, files in os.walk(features_dir):\n",
        "            for file in files:\n",
        "                zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), features_dir))\n",
        "\n",
        "    from google.colab import files\n",
        "    files.download(f'{features_dir}.zip')\n",
        "else:\n",
        "    print(\"Diretório 'features-' não encontrado.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMk0OXUoItOJ"
      },
      "source": [
        "#Eliminar pasta gerada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgn6_l-zY3Ew",
        "outputId": "dd1d920a-c647-4cb8-8a5e-135f7fc61ade"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diretório e arquivo zip removidos com sucesso.\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "features_dir = next((d for d in os.listdir() if d.startswith(\"features-\")), None)\n",
        "\n",
        "if features_dir:\n",
        "    shutil.rmtree(features_dir)\n",
        "\n",
        "if os.path.exists('features.zip'):\n",
        "    os.remove('features.zip')\n",
        "\n",
        "print(\"Diretório e arquivo zip removidos com sucesso.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
